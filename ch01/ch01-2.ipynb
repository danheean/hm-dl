{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Conv2D name=conv2d_1, built=False>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Conv2D 레이어 생성\n",
    "# - filters=10: 10개의 필터(커널) 사용\n",
    "# - kernel_size=(3, 3): 3x3 크기의 커널\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "conv1 = layers.Conv2D(filters=10, kernel_size=(3, 3))\n",
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 26, 26, 10)\n"
     ]
    }
   ],
   "source": [
    "# 2. Conv2D 레이어 적용 테스트\n",
    "# - 입력: (10, 28, 28, 1) → 10개 샘플, 28x28 이미지, 1채널(흑백)\n",
    "# - 출력: (10, 26, 26, 10) → 3x3 커널로 convolution 후 크기가 줄어듦\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.random((10, 28, 28, 1))  # 랜덤 데이터 생성\n",
    "conv_out = conv1(x)  # Conv2D 레이어 적용\n",
    "\n",
    "print(conv_out.shape)  # 출력 shape 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 13, 13, 10)\n"
     ]
    }
   ],
   "source": [
    "# 3. Stride를 사용한 Conv2D\n",
    "# - strides=(2,2): 커널을 2칸씩 이동하면서 convolution 수행\n",
    "# - 출력 크기가 더 작아짐: (10, 13, 13, 10)\n",
    "conv2 = layers.Conv2D(filters=10, kernel_size=(3, 3), strides=(2,2))\n",
    "\n",
    "print(conv2(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 14, 14, 10)\n"
     ]
    }
   ],
   "source": [
    "# 4. Padding='same'과 stride를 함께 사용\n",
    "# - padding='same': 입력과 출력의 크기 비율을 유지하도록 패딩 추가\n",
    "# - stride=(2,2)로 인해 출력이 입력의 절반 크기: (10, 14, 14, 10)\n",
    "conv3 = layers.Conv2D(filters=10, kernel_size=(3, 3), strides=(2, 2), padding='same')\n",
    "\n",
    "print(conv3(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 28, 28, 10)\n"
     ]
    }
   ],
   "source": [
    "# 5. Padding='same'만 사용 (기본 stride=1)\n",
    "# - 입력과 출력의 크기가 동일하게 유지: (10, 28, 28, 10)\n",
    "# - 특징 맵의 크기를 유지하면서 convolution 수행\n",
    "conv4 = layers.Conv2D(filters=10, kernel_size=(3, 3), padding='same')\n",
    "\n",
    "print(conv4(x).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 14, 14, 1)\n",
      "(10, 9, 9, 1)\n"
     ]
    }
   ],
   "source": [
    "# 6. AveragePooling2D 레이어 테스트\n",
    "# - pool_size=2: 2x2 영역의 평균값으로 다운샘플링\n",
    "# - pool_size=3: 3x3 영역의 평균값으로 다운샘플링\n",
    "# - 공간 차원이 줄어들면서 계산량 감소 및 특징 추출\n",
    "pool1 = layers.AveragePooling2D(pool_size=2)\n",
    "pool2 = layers.AveragePooling2D(pool_size=3)\n",
    "\n",
    "print(pool1(x).shape)  # (10, 14, 14, 1) - 절반 크기\n",
    "print(pool2(x).shape)  # (10, 9, 9, 1) - 더 작은 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 7]]\n",
      "tf.Tensor([[  1.860203  -10.448993   -2.4645417]], shape=(1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 7. Dense(완전연결) 레이어 기본 사용\n",
    "# - Dense(3): 3개의 출력 노드를 가진 완전연결 레이어\n",
    "# - 입력 [5, 7]에 대해 랜덤 초기화된 가중치로 계산\n",
    "dense1 = layers.Dense(3)\n",
    "\n",
    "import numpy as np\n",
    "x2 = np.array([[5, 7]])  # 2차원 입력 데이터\n",
    "\n",
    "print(x2)  # 입력 확인\n",
    "print(dense1(x2))  # 출력: (1, 3) 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.65280044, -0.21822304, -0.310812  ],\n",
      "       [ 0.474653  , -0.02614796, -0.33841002]], dtype=float32), array([0., 0., 0.], dtype=float32)]\n",
      "tf.Tensor([[33. 45. 57.]], shape=(1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 8. Dense 레이어의 가중치 확인 및 수동 설정\n",
    "# - get_weights(): 현재 가중치와 편향 확인\n",
    "# - set_weights(): 가중치를 수동으로 설정\n",
    "# - 가중치 행렬: (2, 3), 편향: (3,)\n",
    "print(dense1.get_weights())  # 초기 랜덤 가중치 확인\n",
    "\n",
    "dense1.set_weights([\n",
    "    np.array([[1, 2, 3], [4, 5, 6]]),  # 가중치 행렬 설정\n",
    "    np.array([0, 0, 0])  # 편향을 0으로 설정\n",
    "])\n",
    "\n",
    "print(dense1(x2))  # 새로운 가중치로 계산한 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33. 45. 57.]]\n"
     ]
    }
   ],
   "source": [
    "# 9. Dense 레이어의 동작 원리 확인\n",
    "# - Dense 레이어는 내부적으로 행렬 곱셈(np.dot)을 수행\n",
    "# - 입력 x2와 가중치 행렬의 곱 = Dense 레이어의 출력\n",
    "# - [5, 7] × [[1,2,3], [4,5,6]] = [33, 45, 57]\n",
    "weight = dense1.get_weights()[0]  # 가중치 행렬 추출\n",
    "\n",
    "print(np.dot(x2, weight))  # 수동 행렬 곱셈으로 동일한 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
